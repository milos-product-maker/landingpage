[
  {
    "title": "Test",
    "slug": "test",
    "date": "2025-12-13",
    "author": "Test",
    "tags": [
      "Test"
    ],
    "image": "media/lucid-logo.svg",
    "description": "Test",
    "content": "*   Test\n  \n\n![](media/9TLw1bo4Wr6uKJLQz8lRX6bp8.jpeg)\n\n> ouefasf\n\n| asdsa |     |     |\n| --- | --- | --- |\n| asd |     |     |\n| sad |     |     |"
  },
  {
    "title": "Cryptographic Verification: A Strategy for U.S. AI Export Leadership",
    "slug": "cryptographic-verification-a-strategy-for-us-ai-export-leadership",
    "date": "2025-11-03",
    "author": "Kristian Rönn",
    "tags": [
      "National Security",
      "AI Trade Policy",
      "AI Security",
      "Export Controls"
    ],
    "image": "/media/pE4sNBZQBMDmfBnLeT4iNAVf9V0.png",
    "description": "Turning Sovereign AI Requirements into U.S. Export Opportunities",
    "content": "# Cryptographic Verification: A Strategy for U.S. AI Export Leadership\n\n## The Problem: AI Trade Barriers\n\nThe ambitious U.S. strategy to export the full American AI technology stack has encountered a powerful and predictable countervailing force: the global rise of digital nationalism. The long-held assumption of a single, integrated global digital market has gradually been rendered obsolete. In its place, a fragmented landscape of \"regulatory fiefdoms\" has emerged, driven by a deep-seated desire among nations to assert control over their digital futures.\n\nThe global pursuit of \"Sovereign AI\" is a direct response to recent history. Supply chain disruptions and the clear strategic implications of technological dependence have alarmed governments worldwide. As a result, nations are launching multi-billion-dollar initiatives not just to participate in the AI economy, but to control their own AI infrastructure, data, and models. This has created a paradoxical environment for American technology providers. On one hand, the race for sovereign AI has generated unprecedented demand for U.S.-designed hardware, as allied nations rush to build domestic compute capacity. On the other hand, to ensure this new infrastructure is truly \"sovereign,\" these same nations are erecting complex regulatory barriers that govern data storage, model management, and content control, directly threatening the high-margin software and services that run on that hardware.\n\nThe core of the problem lies in a fundamental conflict of interests. The United States, motivated by legitimate national security and economic concerns, seeks maximum control and visibility over its exported technology. This is essential to prevent misuse, protect intellectual property, and ensure the technology cannot be turned against American interests.\n\nConversely, \"sovereign buyers\"—from highly regulated markets in the European Union to ambitious emerging powers in Asia and the Middle East—demand the exact opposite. They seek maximum sovereignty, which they define as complete control over their critical digital infrastructure and the data that flows through it. They are increasingly skeptical of relying on a technology stack that is ultimately beholden to the laws and strategic interests of another nation. This skepticism is actively fueled by competitors like China, which promotes a narrative of American untrustworthiness, warning of hidden \"backdoors\" and \"kill switches\" in U.S. technology. This narrative erodes the trust necessary for deep technological partnerships and makes the sale of an American-controlled stack more challenging.\n\nThis conflict manifests as a web of national and regional regulations that will increasingly pose barriers to entry in key global markets. The EU's data localization rules, for example, could favor local European cloud providers if US providers cannot provide robust guarantees on where the data goes. Similar trends are arising in the Middle East and Asia. To win the infrastructure race, the United States must offer a solution that seamlessly and technically addresses these sovereignty concerns, moving beyond legal assurances to provide demonstrable proof.\n\n## The Solution: Trust Through Cryptographic Verification\n\nIn the current zero-trust geopolitical environment, policy assurances and contractual obligations are insufficient to overcome the sovereignty paradox. A sovereign buyer concerned about a \"kill switch\" or data access under the U.S. CLOUD Act will not be placated by a clause in a service-level agreement. One viable path to resolving this trust deficit is to build the American AI stack on a foundation of cryptographic verification. This approach moves the basis of trust from the identity of the operator to the provable mathematical properties of the system itself, offering sovereign buyers demonstrable proof of compliance and control.\n\nThe strategic challenge is to bridge the gap between the promise of security and the proof of it. The American technology stack must evolve from a model that says, \"We promise not to access your data,\" to one that can state, \"We have cryptographic protections that make unauthorized access extremely difficult and detectable, and we can prove it to you on demand.\" This shift from policy-based compliance to evidence-based assurance is the key to unlocking high-friction international markets.\n\nThis new paradigm of demonstrable proof is made possible by a confluence of mature technologies that, when integrated, provide a verifiable chain of trust from the silicon to the application.\n\n### Confidential Computing & Trusted Execution Environments (TEEs)\n\nTEEs are secure, isolated areas within a main processor, such as those provided by Intel SGX/TDX or AMD SEV. They create protected memory enclaves where code and data are isolated during processing. Even an administrator with root privileges on the host operating system—or the cloud provider itself—cannot see or modify what is inside the TEE. This provides a powerful guarantee of data confidentiality and code integrity.\n\n### Hardware Roots of Trust (HRoT)\n\nAn HRoT, typically a Trusted Platform Module (TPM), is a dedicated microchip designed to provide secure hardware-based functions. It acts as the immutable foundation of trust for a computing platform. It can securely store cryptographic keys and, most importantly, can measure (cryptographically hash) the state of the system's firmware and software during the boot process, creating a secure log of the platform's configuration.\n\n### Remote Attestation\n\nThis is the protocol that makes the internal state of the system visible to an external party. A remote user (the sovereign buyer) can challenge the TEE or TPM. In response, the hardware provides a signed report containing the measurements of the software running on the system. This report is signed with a cryptographic key that is fused into the silicon and can be verified against the manufacturer's public key. This allows the buyer to receive strong cryptographic evidence of the hardware and software configuration at boot time where their workload is running, confirming that it has not been tampered with and matches an approved configuration.\n\nThis fundamental security architecture is not just confined to CPUs; it is now a critical design pillar across the spectrum of modern AI accelerators. Recognizing that proprietary AI models and sensitive training datasets are immensely valuable assets, manufacturers like NVIDIA, AMD, Intel, and Google embed these hardware primitives directly into their GPUs and TPUs. These foundational technologies enable a range of specific, verifiable guarantees that directly address the concerns of sovereign buyers. These guarantees are not abstract principles but concrete deployment-ready capabilities that the American AI Technology Stack can provide to meet the demand for sovereignty from global customers.\n\n- **A. Data Residency:** Is all data processing and storage confined within our nation's jurisdiction?\n- **B. Confidentiality:** Is citizen and business data encrypted and protected from all unauthorized access?\n- **C. Benchmarks:** Has the AI model been validated against our national benchmarks for performance, safety, and compliance?\n- **D. Usage:** Does the data center, including all model training activities, adhere to local regulations and compute usage restrictions?\n\nVerifiable guarantees fundamentally alter the power dynamic between the technology provider and the sovereign customer. A U.S. company can build and operate the world's most advanced AI infrastructure, while a foreign government or enterprise can use that infrastructure with strong cryptographic assurances that their data and workloads remain exclusively under their control. While customers must still trust the underlying hardware manufacturers and implementation, the reliance on trusting the provider's legal entity or home jurisdiction is substantially reduced—the basis of trust shifts toward verifiable technical controls rather than policy commitments alone.\n\nFurthermore, a platform architected around these principles can transform regulatory compliance from a manual, periodic, and costly audit process into a more automated, semi-continuous, and technically verifiable process. Instead of an auditor reviewing logs to verify data residency, the platform can generate cryptographic attestations that provide strong evidence that a workload ran exclusively on servers within a specific national border and in an isolated environment configured to restrict external network access. This allows U.S. firms to sell verification as a premium, high-margin service, turning trade barriers into a source of competitive advantage, especially in relation to the Chinese AI Technology Stack.\n\n## Deployment Configurations: A Framework for Global Markets\n\nA successful global deployment strategy requires a nuanced understanding of the different ways the American AI stack can be configured, and what international trade barriers exist around each such configuration. The following three-axis model provides a framework for analyzing deployments:\n\n### Axis 1: Operator (The \"Who\")\n\n- **O1: US Entity:** The data center is built, owned, or operated by a U.S. corporation (e.g., AWS, Oracle) or a U.S. government entity.\n- **O2: Host Nation Entity:** The data center is operated by a non-U.S. entity, such as a private French company, a German state-owned utility, or a sovereign wealth fund.\n\n### Axis 2: Jurisdiction (The \"Where\")\n\n- **J1: US Homeland:** The physical data center is located in the United States and is subject to U.S. law, with foreign customers accessing it remotely.\n- **J2: Partner Nation (Regulated):** The physical data center is located within the borders of a partner nation (e.g., France, Germany, Japan) and is subject to its local laws, such as GDPR.\n\n### Axis 3: Technology Stack (The \"What\")\n\n- **S1: US Model on US Hardware:** The complete American stack, featuring a U.S.-developed AI model running on U.S.-designed hardware.\n- **S2: US Model on Foreign Hardware:** A U.S. AI model running on hardware from a non-U.S. manufacturer.\n- **S3: Foreign Model on US Hardware:** A foreign-developed AI model (e.g., France's Mistral) running on U.S.-designed hardware.\n- **S4: Foreign Model on Foreign Hardware:** A completely non-U.S. technology stack.\n\nThese axes define a spectrum of deployment scenarios, each with unique trust and regulatory implications. For example, an O1/J1/S1 deployment (AWS running a U.S. model in Virginia) is the default for many U.S. customers but is the most challenging to sell into high-sovereignty markets. Conversely, an O2/J2/S3 deployment (a German company running a French model on U.S. hardware in Frankfurt) presents a very different proposition that can be tailored to meet stringent EU requirements. The strategic goal should not be to force a single configuration on the world, but to sell a verifiable platform that enables a menu of secure, sovereign-respecting configurations. The product is not the stack; the product is verifiable trust.\n\n## Overcoming the Industry Coordination Problem\n\nThe primary obstacle to deploying a verifiably sovereign American AI Technology Stack is not a lack of technology, but a classic industry coordination problem. The capabilities for verification, based on technologies such as confidential computing and cryptographic attestation exist, yet they remain siloed within specific layers of the technology stack, making it difficult to deliver the integrated, end-to-end assurance that sovereign buyers demand. For example, a chip maker like Intel can attest to its hardware security properties, a cloud provider like Amazon can attest that a virtual machine is running on that chip, and an AI company can attest that its model is untampered with—but these attestations are not standardized or easily composable, leaving the customer unable to verify the entire process end-to-end through a single, unified chain of evidence.\n\nThis creates a \"chicken-and-egg\" problem. While vital work on technical standards is underway in bodies like the Confidential Computing Consortium, Internet Engineering Task Force, and the Open Compute Project, the traditional process of industry-wide consensus and adoption takes decades. Crucially, the United States does not have decades. To win the current AI arms race and secure its technological leadership, it must solve this problem during this presidency. To effectively address the industry coordination problem, the Request for Proposal (RFP) for the American AI Technology Stack should be enhanced to cultivate products for digital trust. This can be achieved by embedding two core principles into the RFP requirements:\n\n### 1) Mandate Integration with Independent Verification Technology Providers\n\nThe RFP should explicitly require that all submitted \"full-stack AI technology packages\" are integrated with a Third-Party Verification Technology Provider. These providers—which include the existing market of technical audit firms, privacy platforms, and cybersecurity companies—would be responsible for aggregating and presenting the cryptographic attestations that build customer trust in privacy, data residency, and system configuration. Their third-party independence is crucial for building impartial trust, as it avoids the inherent conflict of interest that arises when a technology provider, such as a hyperscaler, verifies its own systems.\n\nMoreover, by making third-party verification a prerequisite for purchase, the financial burden of complying with international AI trade barriers shifts from American technology companies to the sovereign buyers themselves. This strategic shift not only alleviates the compliance costs but also cultivates a new, lucrative market for American firms specializing in verification technology.\n\n### 2) Align Federal Incentives to Build the Verification Market\n\nThe RFP should directly link the federal financing tools mentioned in the Executive Order to the costs incurred by both the stack providers and their Verification Technology Provider partners. This approach addresses the current economic misalignment by funding the development and integration of the verification layer. By offering loans, guarantees, and other de-risking mechanisms, the government can accelerate the creation of a robust and competitive verification market.\n\nA priority AI export package selected under these terms would help establish a de facto industry standard for verifiable sovereignty, positioning the American AI Technology Stack as not only the most powerful but also the most demonstrably trustworthy solution for sovereign buyers on the global stage."
  },
  {
    "title": "Navigating the Maze of AI and Data Sovereignty in the EU",
    "slug": "navigating-the-maze-of-ai-and-data-sovereignty-in-the-eu",
    "date": "2025-08-29",
    "author": "Connor Dunlop",
    "tags": [
      "Data Sovereignty",
      "EU Policy",
      "AI Security"
    ],
    "image": "/media/TAgIxThuWHOm5a9n0FTDD5ddk.png",
    "description": "Can hardware-rooted attestation provide a verifiable proof of compliance across EU regulations?",
    "content": "# Navigating the Maze of AI and Data Sovereignty in the EU\n\nGovernments across the European Union are increasingly focused on AI and data sovereignty. This trend is driven by a range of new regulations, from broad frameworks like the EU Cybersecurity Act to sectoral rules such as health, finance, government and defence. \n\nFor any organisation in Europe's digital ecosystem - from cloud, hardware, and network infrastructure providers to the public and private sector entities deploying critical systems - navigating this landscape has become a strategic necessity.\n\nIn this post, we'll break down the key regulations driving these sovereignty obligations and introduce our solution for seamlessly and securely proving the sovereignty of your critical AI workloads and data: Sovereign Certificates.\n\n## The Foundation: The EU Cybersecurity Act (CSA) and EUCS\n\nThe EU Cybersecurity Act (CSA) serves as the legal foundation for harmonised, EU-wide cybersecurity certifications. It doesn't list specific controls but creates the rulebook for schemes like the upcoming EU Cloud Certification Scheme (EUCS).\n\nA critical part of the CSA is Article 52, which defines three \"assurance levels\":\n\n- **Basic:** Protects against known risks.\n\n- **Substantial:** Protects against attackers with limited resources.\n\n- **High:** strongest assurance for critical use cases.\n\nThis 'High' level provides the legal justification for embedding sovereignty requirements into EU-wide certifications. Drafts of the EUCS have considered doing just that by defining a key security objective as protecting data from unlawful access by third-country authorities, directly justifying the need for sovereignty controls. \n\n**Raising the bar: France's SecNumCloud**\n\nSecNumCloud has already implemented strict sovereignty criteria. Drafted by the French cybersecurity agency (ANSSI),  it is currently the strictest sovereignty-focused certification in Europe. It goes far beyond simple data localisation to make a provider legally and structurally immune to non-EU legal overreach.\n\nKey sovereignty requirements in SecNumCloud include:\n\n- **Protection Against Non-EU Law:** The provider’s corporate structure and headquarters must be in the EU. Strict limits are placed on non-EU ownership. \n\n- **Data and Operations Localisation:** All customer and technical data, as well as all administration and supervision, must be located and performed within the EU.\n\n- **Legal Framework:** Service agreements must be governed by the law of an EU member state.\n\n## A Sector-Specific Example: The European Health Data Space (EHDS) \n\nThe trend towards sovereignty is particularly clear in critical sectors. The **European Health Data Space (EHDS)** is a prime example. This regulation aims to create a single market for digital health data, allowing researchers and innovators to access high-quality health data for the public good (known as \"secondary use\").\n\nTo protect this highly sensitive information, the EHDS regulation mandates that this data can only be accessed and processed within **secure processing environments**. A core requirement is that these environments must be physically and operationally managed **within the EU**. Crucially, data within these environments **cannot be transferred to or accessed from third countries**. This creates a clear, legally binding sovereignty requirement for anyone wanting to access European health data via this initiative. \n\n## Sector-Specific Driver 2: Finance and the Digital Operational Resilience Act (DORA) \n\nSimilarly, the financial sector is facing intense pressure to guarantee sovereignty. The **Digital Operational Resilience Act (DORA)** harmonizes digital resilience rules for all financial entities in the EU. \n\nA key focus for supervisory authorities, including the **European Central Bank (ECB)**, is the sector's heavy reliance on external cloud providers. Recent ECB guidance on outsourcing signals increasing scrutiny on the **location of hosted data and operations**. This is pushing banks, insurers, and investment firms to demand stronger guarantees of data sovereignty to ensure their operational resilience and regulatory compliance under DORA.\n\n## Our Solution: Sovereignty Certificates\n\nNavigating these complex requirements can be both burdensome and technically unverifiable: usually relying on strict but blunt operational or personnel controls and contractual promises, not verifiable proof. **Sovereignty Certificates offer a streamlined, targeted solution** to ensure customers can simply and securely verify that their AI workloads and related data remain within their chosen jurisdiction. These both compliment and are meaningfully differentiated from the sovereignty standards mentioned in this article:\n\n- **Complementary:** By meeting our standard, your organisation implements the core technical sovereignty controls required by SecNumCloud, the proposed 'High' level of the EUCS, and sector-specific rules like the EHDS. This simplifies the path to full certification and helps meet obligations under the GDPR, Data Act, and ISO 27001.\n\n- **Differentiated:** For customers who need to guarantee sovereignty without the overhead of a full SecNumCloud qualification, our certificates provide a powerful \"Sovereignty Guarantee.\" This unlocks new, sensitive sectors like health and finance, offering a distinct competitive advantage.\n\nThe gap between regulatory requirements and technical capabilities is widening. While regulations demand proof, traditional approaches offer only promises. Sovereignty Certificates bridge that gap with hardware-rooted verification that regulators can trust and customers can verify. \n\n## Annex - EU Legislation Incentivising Digital Sovereignty\n\n| **EU Law / Regulation**\n\n | **Key Sovereignty Incentive(s)**\n\n | **How it Works (Simplified)**\n\n\n| **EU Cybersecurity Act (CSA)**\n\n | Creates a legal basis for sovereignty requirements in EU-wide certifications.\n\n | The Act's **'High' assurance level** is designed to protect against state-level threats, justifying the need for controls against non-EU legal access.\n\n\n| **EUCS (Proposed)**\n\n | Aims to create a harmonized, high-assurance \"sovereign cloud\" standard for the EU.\n\n | The draft scheme proposes mandatory EU-based corporate structures and technical immunity from non-EU laws for its highest level of certification.\n\n\n| **Data Act**\n\n | Legally protects EU data from unlawful third-country government access requests. Facilitates switching between cloud providers to prevent vendor lock-in.\n\n | It requires providers to reject non-EU government access requests unless they are based on an international treaty and removes technical/financial barriers to switching services.\n\n\n| **GDPR**\n\n | Imposes strict conditions on the transfer of personal data outside the EU.\n\n | Data transfers to third countries are only permitted if that country provides an \"adequate\" level of data protection, creating a strong incentive to keep data within the EU.\n\n\n| **NIS2 Directive**\n\n | Mandates that critical entities secure their supply chains and manage risks from ICT suppliers.\n\n | Forces essential entities (in energy, transport, health, etc.) to scrutinize their cloud providers, favoring those who can guarantee data and operations are managed within the EU to minimize supply chain risks.\n\n\n| **Digital Operational Resilience Act (DORA)**\n\n | Requires financial entities to manage and control risks from third-party ICT providers, including cloud services.\n\n | Pushes financial firms to demand stronger guarantees on data location and operational control from suppliers to ensure resilience and reduce cross-border dependency risks.\n\n\n| **European Health Data Space (EHDS)**\n\n | Mandates a sovereign environment for the use of health data for research and innovation.\n\n | The regulation requires that sensitive health data for secondary use is only processed in a secure environment within the EU, with no access from third countries.\n\n\n| **SecNumCloud (France)**\n\n | Provides a clear, auditable \"gold standard\" for what a sovereign service looks like.\n\n | Although a national standard, its strict rules on EU ownership, control, and operations heavily influence the EU-level debate and the design of the EUCS."
  },
  {
    "title": "AI Exports at Scale Require Verification, Not Just Counting",
    "slug": "ai-exports-at-scale-require-verification-not-just-counting",
    "date": "2025-08-08",
    "author": "Kristian Rönn",
    "tags": [
      "National Security",
      "AI Trade Policy",
      "AI Security",
      "Export Controls"
    ],
    "image": "/media/wbfAO30etTdjdRF5oESER55KaA.png",
    "description": "To fulfill the promise of the AI Action Plan, export controls must evolve beyond physical counting and embrace scalable, hardware-rooted verification.",
    "content": "# AI Exports at Scale Require Verification, Not Just Counting\n\n## Introduction: The Gap Between Policy Assumptions and Technical Reality\n\nIn his July 30, 2025 address at the Center for Strategic and International Studies, White House Office of Science and Technology Policy Director Michael Kratsios outlined the Trump Administration's approach to AI export control enforcement. While acknowledging resource constraints at the Bureau of Industry and Security (BIS), Kratsios expressed confidence that physical chip tracking presents manageable challenges, characterizing AI hardware as \"massive racks that are tons in weight\" that are difficult to relocate and easy to monitor—implying that simple physical inspections could suffice.\n\nThis assessment, while reflecting legitimate policy optimism with the sensible aim of scaling American AI exports rapidly and securely, appears to underestimate both the technical portability of export-controlled AI accelerators and the effective methods already being used to circumvent those export controls. Recent high-profile cases of AI chip smuggling and transshipment efforts  reveal a more complex enforcement challenge that requires technological solutions beyond traditional physical inspection approaches. Fortunately, there are scalable technical solutions that can effectively verify the location and status of AI chips, providing the \"tools that BIS needs to do the enforcement activities\" which Kratsios rightly signalled is necessary to secure American AI dominance.\n\n## The Portability Reality: Individual Components, Not Integrated Systems\n\n### Technical Specifications Contradict Immobility Claims\n\nThe characterization of AI chips as immobile infrastructure misconstrues their actual technical attributes. Export-controlled AI accelerators are individual, highly portable components rather than integrated rack systems. As one customs official noted in recent smuggling case documentation, individual AI accelerators are \"comparable in size to a Nintendo Switch\" rather than massive installations requiring industrial equipment for transport.\n\n**NVIDIA H100 PCIe Specifications:**\n- **Weight**: 2-5 pounds per card\n- **Form Factor**: Standard dual-slot PCIe component\n- **Power Draw**: 350W (within desktop system envelopes)\n- **Dimensions**: Comparable to a large graphics card\n\nThis modularity has real enforcement implications. Modern server architectures specifically enable hot-swappable accelerator modules. Of a typical $50,000 AI server cost, approximately $40,000 represents the accelerator cards themselves—components that can be removed in minutes while leaving empty enclosures that appear fully operational during casual inspection. With accelerator modules accounting for the bulk of server value, actors on the BIS entity list can readily remove or transship controlled components through global gray markets while leaving enclosures behind that appear operational.\n\n### Documented Cases of Physical Diversion Demonstrate Practical Challenges\n\nThese challenges aren't theoretical. Enforcement authorities have uncovered multiple instances in recent months that demonstrate just how easily AI chips can be diverted and the sophisticated methods already employed to circumvent the current export control system.\n\n**Singapore Smuggling Network (2025):** Authorities charged three individuals with smuggling $390 million worth of NVIDIA chips, including H100 and B200 models. The operation successfully transported individual accelerator cards through standard commercial channels before detection.\n\n**Student Transport Methods:** Documentation reveals students successfully transported 6 NVIDIA compute cards in personal luggage, declaring them at $100 each to customs authorities. The compact nature of individual accelerators enables concealment within routine travel patterns.\n\n**Commercial-Scale Evasion:** Reuters reported that \"over $1 billion worth of banned NVIDIA chips entered China in Q2 2025 alone\" through various smuggling networks. These operations relied on the portability of individual components rather than attempting to relocate entire server systems.\n\n## The Chinese AI Training Ecosystem: Built on Smuggled Hardware\n\n### DeepSeek and the Underground Economy\n\nRecent analysis suggests that Chinese AI capabilities, including breakthrough models like DeepSeek, rely heavily on smuggled NVIDIA hardware. A [recent report from the Center for a New American Security](https://www.cnas.org/publications/reports/countering-ai-chip-smuggling-has-become-a-national-security-priority) showed that over 100,000 export controlled chips were smuggled into China in 2024 alone, with a median estimate of 140,000 chips. Public reporting cited documents individual graymarket orders worth up to $120 million for shipments of thousands of H100 chips.\n\n**Gray Market Pricing Indicates Robust Demand:** Market signals corroborate these findings. Smuggled H100s in China sell in gray markets for significant markups—often exceeding 50% over U.S. MSRP—commanding prices of $45,000 or more per chip. This price differential indicates both substantial demand and successful supply networks operating beyond regulatory oversight.\n\n**Training Infrastructure Adaptation:** Chinese research institutions have developed sophisticated techniques for maximizing training efficiency using smaller, distributed clusters of smuggled hardware. As one industry analyst observed, \"Chinese labs are training 90% of their models using smuggled components integrated into seemingly legitimate research infrastructure.\"\n\n### Underground Support Networks\n\n**Shenzhen Repair Services:** Underground repair services in Shenzhen now handle \"500 banned GPU repairs monthly,\" indicating a mature support ecosystem for smuggled hardware. These services provide the technical infrastructure necessary to maintain operational capability for components obtained through illicit channels.\n\n**Shell Company Aggregation:** Chinese firms have established \"multiple shell companies placing small orders across third countries to aggregate restricted hardware,\" according to CNAS research. This approach exploits regulatory thresholds while building substantial computational capabilities.\n\n## BIS Resource Constraints: The Enforcement Reality\n\n**Personnel and Capability Limitations:** Several policymakers have expressed unwarranted optimism about the ease of AI export control enforcement—often grounded in technical misunderstandings about how modular, high-value AI accelerators can be moved, hidden, or repurposed. With only [a portion of 585 positions overseeing $486.4 billion](https://www.gao.gov/assets/gao-25-107431.pdf?utm_source=chatgpt.com) in annual licensed exports, BIS and its other government partners operate under real-world constraints. The task of overseeing hundreds of billions of dollars in dual-use technologies with limited personnel and global reach is an inherently difficult mission. And despite the dedication of its staff, BIS must operate in a system where traditional tools—periodic inspections, documentation audits, and license compliance checks—were not designed with modular AI accelerators in mind. The Government Accountability Office noted that BIS field offices \"lack analytical tools and personnel for systematic risk analyses\" and have \"no systematic approach to identifying high-risk entities.\" In short, physical counting approaches simply exceed current BIS operational capabilities.\n\nCompounding the challenge, frontline export control officers—of which BIS has only dozens to monitor global compliance—often lack access to real-time risk assessments or specialized inspection tools. Field inspections may catch obvious violations, but they are not well-equipped to detect partial diversion, distributed system assembly, or chip-level concealment. Legitimate industry stakeholders, meanwhile, frequently voice concern about the operational burden of traditional compliance mechanisms, especially when physical inspections risk downtime or data disruption. These constraints reflect systemic design gaps, not lack of effort.\n\nTo succeed in this new environment, enforcement strategies must evolve alongside the technology landscape they are meant to secure.\n\n**Customer Impact and Operational Challenges**\n\n**Industry Resistance to Intrusive Monitoring:** Many legitimate customers consider physical counting \"invasive and an operational hindrance.\" This resistance creates pressure to minimize inspection frequency and thoroughness, potentially enabling evasion through timing manipulation.\n\n**Detection Reliability Problems:** Empty server enclosures can be fitted with \"cheap PCB replicas\" that appear operational during visual inspection while containing no actual processing capability. Without sophisticated technical inspection equipment, physical counting may provide false confidence in compliance verification.\n\n## Technical Evasion Capabilities: Beyond Physical Smuggling\n\n### Distributed Training Approaches\n\nRecent research demonstrates viable approaches for training large models across globally distributed, smaller GPU clusters that appear as routine cloud usage rather than concentrated training operations.\n\n**Geographic Distribution:** Google trained Gemini Ultra across multiple data centers using geographic distribution methods that major technology companies routinely employ. Similar approaches enable sophisticated actors to utilize distributed smuggled hardware while appearing to comply with concentration-based detection methods.\n\n**OpenDiLoCo Research:** Academic research projects like OpenDiLoCo enable \"training across poorly connected clusters by reducing synchronization frequency,\" demonstrating practical approaches for utilizing smuggled hardware through distributed networks that evade traditional monitoring approaches.\n\n### Advanced Obfuscation Techniques\n\n**Power Signature Manipulation:** Engineers have developed \"power smoothing commands specifically designed to obscure training signatures,\" making detection through power consumption analysis unreliable. Empirical measurements show AI training creates \"instant fluctuations of power consumption across the datacenter on the order of tens of megawatts,\" complicating steady-state detection approaches.\n\n**Traffic Pattern Obfuscation:** Modern distributed training uses encrypted protocols that generate \"elevated rates of false positives\" in detection systems. Collective communication operations create irregular patterns difficult to distinguish from other high-bandwidth applications.\n\n## The Path Forward: Technology-Enabled Verification\n\n### Hardware-Rooted Authentication\n\nRather than relying solely on physical counting, robust export control enforcement requires hardware-level verification systems that cannot be circumvented through component substitution or geographic relocation.\n\n**Cryptographic Attestation:** Modern AI accelerators incorporate Trusted Execution Environments (TEEs) capable of generating unforgeable location and usage attestations. These systems provide continuous verification rather than periodic inspection snapshots.\n\n**Real-Time Monitoring:** Location verification systems can provide continuous, automated monitoring that supplements rather than replaces traditional enforcement approaches while addressing the resource constraints Director Kratsios correctly identified.\n\n### Policy Integration Opportunities\n\nThe Trump Administration's emphasis on reducing regulatory burden while maintaining security creates opportunities for technology-enabled compliance that reduces both enforcement costs and industry operational impact.\n\n**Automated Compliance:** Hardware-rooted verification systems can provide the \"tools that BIS needs to do the enforcement activities\" while reducing the invasive inspection requirements that concern legitimate customers.\n\n**Strategic Resource Allocation:** By automating routine compliance verification, BIS resources can focus on sophisticated evasion attempts and strategic enforcement priorities rather than manual counting activities.\n\n## Conclusion: Bridging Policy Optimism with Technical Realities\n\nCharacterizing AI chip tracking as a simple physical counting exercise underestimates both the technical sophistication of evasion methods and the portable nature of the hardware itself.\n\nThe documented success of smuggling efforts, the reliance of Chinese AI development on illicit hardware, and the inherent limitations of manual inspection approaches suggest that effective export control enforcement requires technological solutions that complement traditional regulatory approaches.\n\nThe Trump Administration's AI Action Plan creates opportunities to deploy verification technologies that address these challenges while supporting the broader goal of American AI dominance. Rather than choosing between regulatory effectiveness and industry cooperation, technology-enabled approaches can enhance both enforcement capability and operational efficiency.\n\nThe strategic imperative remains clear: ensuring that America's AI leadership translates into sustained competitive advantage requires verification systems adequate to the technical sophistication of both the technology and those who seek to circumvent controls. Physical counting, while important, represents only the foundation of a comprehensive approach that must evolve alongside the threats it seeks to address.\n\nThe challenge is not whether export controls matter—they clearly do—but whether enforcement approaches can keep pace with the technical realities of an increasingly sophisticated global technology landscape. *If America wants to lead in building the AI stack for the world, it must also lead in verifying that stack is protected.*"
  },
  {
    "title": "America First AI Policy in Action",
    "slug": "america-first-ai-policy-in-action",
    "date": "2025-07-15",
    "author": "Kristian Rönn",
    "tags": [
      "National Security",
      "AI Trade Policy",
      "AI Security",
      "Semiconductors"
    ],
    "image": "/media/oole08QnB2huPcp75s2WqGn8uMQ.png",
    "description": "The Congressional roadmap for scaling American AI leadership globally—and the verification technologies needed to execute it",
    "content": "# America First AI Policy in Action\n\n## How Technical Infrastructure Could Unlock Trillions in US Technology Exports\n\nThe $1.3 trillion Stargate deal sits at the intersection of two powerful forces shaping American AI policy. On one side, Congressional leaders are calling for stricter export controls—House Select Committee Chairman John Moolenaar's [recent letter to Commerce Secretary Howard Lutnick](https://selectcommitteeontheccp.house.gov/sites/evo-subsites/selectcommitteeontheccp.house.gov/files/evo-media-document/america-first-ai-policy_letter.pdf) outlines eight specific requirements for limiting AI diffusion while maintaining security. On the other side, OpenAI's launch of \"OpenAI for Countries\" signals the industry's push for aggressive global expansion.\n\nThese forces appear contradictory: more controls versus more diffusion. But technology creates a third path where both vectors align. The right verification infrastructure doesn't just enable stricter controls—it enables more exports by providing the security assurance that makes large-scale partnerships possible. Instead of choosing between growth and security, hardware-governed compute makes both achievable simultaneously.\n\n### The Congressional Framework: Eight Pillars of AI Export Policy\n\nChairman Moolenaar's letter to Secretary Lutnick provides a detailed roadmap for America First AI policy, with specific technical requirements that could enable unprecedented export growth:\n\nThe Stargate deal's 500,000 advanced chips illustrate why existing export control systems face architectural limitations. A Business Development manager at a major OEM recently revealed: \"In CEE alone, we have about 10,000 GPUs worth of projects locked because of export licenses. It kills projects as investors choose different markets where the likelihood of getting a positive response from the BIS (Bureau of Industry and Security) on a shorter turn-around time is higher.\"\n\nScale that to the Congressional vision of multiple trillion-dollar partnerships, and the bottleneck becomes clear.\n\n#### Policy Pillars with Technical Solutions\n\nThe Congressional framework maps directly to emerging verification technologies that could enable the scale of export growth envisioned.\n\n#### The Scale Challenge: Why Traditional Approaches Fall Short\n\nTraditional export control approaches face an impossible tradeoff for large-scale AI partnerships: you can optimize for scale, speed, or security—but not all three simultaneously. The Congressional framework demands all three.\n\nThe Congressional requirements suggest that hardware-based verification could be the only approach that delivers all three simultaneously.\n\n### The Implementation Challenge: Scale vs. Speed vs. Security\n\n### Technical Solutions for Policy Implementation\n\n#### Real-Time Location Verification\n\nThe requirement for \"city- or state-level location reporting\" with automatic diversion notification points to delay-based location verification systems that measure speed-of-light travel times between chips and verification stations. This creates spoof-resistant location proof that GPS-based systems cannot match.\n\n#### Compute Infrastructure Visibility\n\nMonitoring the 49% overseas capacity limit and 10% single-partner training compute cap requires systems that can track Total Compute Power across jurisdictions in real-time. This involves converting chip deployments to computational capacity and maintaining running totals per partner nation, but also hinges heavily on the actual understanding of where the chips are.\n\n#### Workload Classification\n\nDistinguishing training from inference to keep frontier model weights under US jurisdiction requires analyzing usage patterns—burst vs. constant loads, memory access patterns, and computational intensity signatures that indicate the type of AI workload being executed in a particular jurisdiction.\n\n#### Integrated Security Monitoring\n\nThe requirement for tamper-evident monitoring suggests systems where security verification is embedded directly into the compute infrastructure rather than added as an overlay, providing continuous attestation of system integrity.\n\n### The Stargate Template: Scaling Beyond Bilateral Deals\n\nIf successfully implemented, the Stargate partnership could create a replicable template for America First AI policy execution. The key insight is that verification technology doesn't just enable individual deals—it creates the infrastructure for systematic scaling.\n\nCongressional leaders envision not just the UAE partnership, but a global ecosystem of AI partnerships that reinforce US technological leadership. Each successful deployment creates precedent for faster approval of subsequent deals.\n\n#### Economic Multiplier Effects\n\nThe letter emphasizes that \"higher-income partners, such as the UAE, will be able to invest dollar-for-dollar in U.S. infrastructure, furthering U.S. AI capability and capacity.\" This creates a positive feedback loop where export success strengthens domestic AI development.\n\n#### Competitive Positioning\n\nEarly implementation of verification requirements could establish technical standards that become industry norms, extending US influence through infrastructure rather than just policy.\n\n#### Standards Setting\n\n### The OpenAI for Countries Precedent\n\nOpenAI's recent launch of \"OpenAI for Countries\" demonstrates the market demand for scaled international AI partnerships. The initiative suggests that leading AI companies are ready to expand globally, but need the regulatory framework and technical infrastructure to do so securely.\n\nThe Congressional requirements provide the policy framework. Verification technology provides the technical infrastructure. The combination could unlock the trillions in export opportunities that Chairman Moolenaar envisions.\n\n### Beyond Export Control: Technology as Policy Enabler\n\nThe Congressional framework suggests a fundamental shift in how export control technology is conceived. Rather than barriers to trade, verification systems become enablers of strategic partnerships that wouldn't otherwise be possible.\n\nThis approach transforms the value proposition for international partners. Instead of accepting intrusive oversight, they gain access to cutting-edge verification infrastructure that provides independent security assurance while preserving operational sovereignty. Moreover, the same underlying technology could maybe be leveraged to provide additional value, for example through data sovereignty capabilities—offering customers cryptographic proof of where their data is processed. This dual-purpose approach means verification infrastructure isn't just a compliance cost, but a value-generating asset that creates new market opportunities.\n\n### Conclusion: The Infrastructure for American AI Leadership\n\nThe Congressional framework for America First AI policy is ambitious but achievable—if the right technical infrastructure exists. The Stargate deal provides the first test case, but success requires thinking beyond individual partnerships to the systematic scaling of US AI exports.\n\nThe technical requirements are clear: location verification, compute monitoring, workload classification, and integrated security systems. The policy framework exists. The market demand is evident through a plethora of delayed projects in sensitive regions or initiatives like OpenAI for Countries.\n\nWhat remains is execution. The organizations that can deliver verification technology at the scale the Congressional framework envisions will enable the next phase of American AI leadership—one where technological excellence and export growth reinforce each other rather than compete.\n\nThe trillions in potential deals that Congressional leaders envision aren't just economic opportunities—they're the foundation for an AI ecosystem that extends American technological leadership globally. The verification infrastructure to make this vision reality is the next frontier in AI policy implementation."
  },
  {
    "title": "The $16.8 Billion Annual Cost of AI Chip Smuggling",
    "slug": "the-16-8-billion-annual-cost-of-ai-chip-smuggling",
    "date": "2025-06-12",
    "author": "Kristian Rönn",
    "tags": [
      "National Security",
      "AI Trade Policy",
      "Semiconductors",
      "AI Security"
    ],
    "image": "/media/TEthdbacyS4UDO7PWYVxAsLXUlw.jpeg",
    "description": "How Illicit Semiconductor Trade is Draining American Innovation and What Technology Can Do About It",
    "content": "# The $16.8 Billion Annual Cost of AI Chip Smuggling\n\nWhile policymakers debate the future of AI regulation, a silent economic hemorrhage is already underway. Advanced AI chips—the engines of artificial intelligence—are flowing out of American control at an alarming rate, carrying with them not just hardware, but the entire economic potential of the AI revolution. Analysis of current smuggling patterns suggests this illicit trade is draining approximately **$16.8 billion annually** in direct economic value from the United States¹'². But the true strategic cost may be far greater.\n\n## The Hidden Economic Drain\nThe scale of AI chip smuggling defies easy comprehension. An upcoming report from the Center for New American Security (CNAS) estimates that **100,000 export-controlled AI chips** were smuggled into China in the past year alone, representing between 10-50% of China's total AI model-training capacity³. These aren't just components disappearing into a black market—they're **strategic assets** being systematically diverted to fuel adversarial AI development.\n\nConsider the arithmetic of this theft. A single Nvidia H100 chip commands approximately **$28,000** on the legitimate market⁴. But investigative journalists have identified at least **$800 million worth** of smuggled AI chip shipments since the implementation of 2023 export controls⁵. Individual incidents, such as a $390 million Nvidia server heist in Malaysia, illustrate both the sophisticated methods and enormous values at stake⁶.\n\n*As the CNAS report notes: \"Tens to hundreds of thousands of high-performance AI chips are smuggled into China annually, representing a significant portion of its illicitly acquired AI model-training capacity.\"³*\n\nThe smuggling networks themselves have evolved into sophisticated operations involving shell companies, intermediaries in third countries like Malaysia and Singapore, and even large-scale physical theft. A recent House Select Committee report found that the Chinese AI platform DeepSeek was \"likely built using stolen U.S. technology\" and relies on smuggled Nvidia chips, including A100s, H800s, and H100s⁷.\n\n### Current Enforcement: A $57 Million Response to a Multi-Billion-Dollar Problem\nThe disparity between the scale of the challenge and available resources is stark. The Bureau of Industry and Security's (BIS) enforcement budget was **$57 million in FY2024**⁵—a figure dwarfed by the hundreds of millions in smuggled chips identified by journalists alone. This resource gap reflects a broader challenge: traditional export controls, designed for an earlier era of technology competition, are proving inadequate against adaptive adversaries with strong economic incentives to circumvent them.\n\nMeanwhile, U.S. companies bear the compliance costs. Nvidia has reported an **$8 billion revenue hit** from unsellable inventory and licensing restrictions, plus a separate **$5.5 billion charge** tied to controls on chip sales to China⁸. When export controls are easily bypassed through smuggling, these compliance costs become a \"tax\" that fails to achieve its strategic objective.\n\n## Beyond Hardware: The Strategic Value at Stake\nUnderstanding the true cost of AI chip smuggling requires looking beyond the hardware's sticker price to its role as an **economic multiplier**. According to Nvidia's own projections, companies can achieve a return of **$5 to $7 for every dollar invested** in AI chips over a four-year operational period⁹. This isn't just marketing hyperbole—it reflects the fundamental reality that AI chips are the primary capital equipment in what industry observers call \"AI factories.\"\n\n### The OpenAI Economy: Where Hardware Drives Trillion-Dollar Valuations\nConsider OpenAI's trajectory. Valued at an estimated **$300 billion** with **$4 billion in revenue** for 2024¹⁰, the company plans to have **64,000 Nvidia Blackwell chips** operational by the end of 2026—representing roughly **$3.84 billion in chip investments** alone. OpenAI's projected compute spending with Microsoft for 2025 is **$13 billion**¹⁰, underscoring how AI chip access directly translates to economic power.\n\nCoreWeave, the AI-chip-native cloud provider, tells a similar story. Recently targeting an IPO valuation of **$35 billion** on revenues of **$1.9 billion**¹¹, the company's entire business model is built upon access to Nvidia's H100s, A100s, and GH200s. Its **$7.9 billion in debt** and **$15.1 billion in Remaining Performance Obligations**¹¹ reflect the capital-intensive nature of AI infrastructure—and the enormous value it generates.\n\n*\"Each AI chip retained within allied economies represents a 'seat' in the innovation theater of the AI revolution.\"*\n\n### The Innovation Multiplier Effect\nThe broader AI market validates this hardware-driven value creation. The market for generative AI chips alone was worth over **$125 billion in 2024**—representing more than 20% of total chip sales¹². AMD's CEO Lisa Su projects the total addressable market for AI accelerator chips to reach **$500 billion by 2028**¹², larger than the sales for the entire chip industry in 2023.\n\nBut the economic impact extends far beyond chip sales. Goldman Sachs projects that AI could increase global GDP by **$7 trillion over the next decade**¹³. McKinsey estimates **$17.1 to $25.6 trillion** in annual value from AI¹³. These projections aren't just about software—they're fundamentally dependent on access to the underlying hardware that makes AI possible.\n\nWhen advanced AI chips are smuggled away from allied economies, they take this economic potential with them. The **$16.8 billion annual drain** represents not just lost hardware, but a diminished capacity for AI-driven research, development, and deployment within the United States and allied nations—economic value that instead flows to strategic competitors.\n\n## The Compounding Cost of Inaction\nThe **$16.8 billion in annual economic value** currently being diverted through AI chip smuggling represents just the direct, measurable impact. But this figure understates the true strategic cost, which compounds over time through several mechanisms:\n\n### Accelerated Adversarial Capabilities\nChina has demonstrated a decades-long strategy of leveraging technology transfer—both legitimate and illicit—to advance its economic and military capabilities. Economic espionage and intellectual property theft, largely attributed to China, already cost the U.S. economy an estimated **$300-600 billion annually**¹⁴. Smuggled AI chips become force multipliers for these activities, potentially enhancing capabilities for cyber espionage, surveillance systems, and military AI development.\n\nThe recent revelation that DeepSeek was built using smuggled U.S. chips illustrates this dynamic perfectly. When DeepSeek announced its capabilities, U.S. technology stocks experienced a **$1 trillion decrease in value**¹⁵, demonstrating how adversarial AI development—enabled by smuggled U.S. hardware—can directly impact American economic interests.\n\n### Erosion of Innovation Ecosystem Advantages\nThe United States currently maintains what experts call the \"most defensible advantage\" in AI: total compute capacity. This advantage creates a virtuous cycle—greater compute enables more experimentation, faster model development, wider AI deployment, and consequently more data to fuel even better models.\n\n*\"The true metric of AI leadership lies not just in developing advanced models but in the ability to deploy and integrate AI systems at scale across the economy.\"*\n\nEach smuggled chip disrupts this virtuous cycle for the U.S. while potentially accelerating it for competitors. The cumulative effect threatens America's position in what many consider the most economically transformative technology in history.\n\n### National Security and Economic Convergence\nThe national security implications carry their own economic costs. Advanced AI systems have been explicitly recognized as potential existential threats by AI lab CEOs, Nobel laureates, and leading researchers. Current AI models can already assist in engineering dangerous pathogens, while advanced computing clusters could enable adversaries to enhance military applications, support sophisticated cyber operations, and assist in mass surveillance systems.\n\nThe military applications alone justify concern. Lawmakers have warned that smuggled chips could help the Chinese Communist Party design advanced weaponry or accelerate work on Artificial General Intelligence. The urgency has been compared to controlling nuclear technology—and for good reason.\n\n## A Technology-Enabled Path Forward\nThe challenge of AI chip smuggling cannot be solved through traditional export controls alone. The adaptive nature of smuggling networks, combined with the enormous economic incentives involved, demands a technological response that matches the sophistication of the threat.\n\n### Hardware-Based Location Verification\nThe solution lies in making smuggling economically unfeasible through **technology-enabled verification systems**. The bipartisan Chip Security Act, recently introduced in Congress, envisions exactly this approach: requiring location verification mechanisms on export-controlled chips, mandating reporting of diversions, and establishing rules to prevent unauthorized use¹⁶.\n\nAdvanced location verification technologies, such as **delay-based verification systems**, offer promising countermeasures¹⁷. These systems use chips to communicate with networks of \"landmark\" servers, determining location based on signal travel time—a method far more secure against spoofing than GPS and functional even within data centers where GPS signals struggle to penetrate.\n\nCompanies like Google are already using similar technologies to track their in-house AI chips¹⁷. The concept scales naturally: as the verification infrastructure expands, it becomes increasingly difficult and expensive for smugglers to operate undetected.\n\n### The Path to Prevention\nConservative projections suggest that robust tracking technologies, combined with enhanced enforcement, could dramatically reduce this **$16.8 billion annual economic drain** when widely implemented with effective international cooperation. While determined adversaries will inevitably attempt circumvention, the key is raising the cost and complexity of smuggling operations while improving detection capabilities.\n\nThis technological approach offers several advantages over traditional controls:\n\n- **Continuous Verification**: Unlike periodic audits, technology-enabled systems provide ongoing location confirmation\n\n- **Scalable Implementation**: Software-based solutions can be deployed across thousands of chips simultaneously\n\n- **Economic Efficiency**: Automated verification reduces the human resources required for monitoring\n\n- **Deterrent Effect**: Known tracking capabilities discourage smuggling attempts\n\n### International Cooperation and Industry Partnership\nSuccess requires coordination across multiple dimensions. Allied nations must implement complementary verification requirements, closing the jurisdictional arbitrage that smugglers currently exploit. Industry partnership is equally critical—chip manufacturers, cloud providers, and system integrators all play roles in the broader ecosystem that enables or prevents smuggling.\n\nThe development of verification technologies also represents an economic opportunity for U.S. firms. Creating robust, tamper-resistant tracking systems requires expertise in cryptography, secure hardware design, and distributed systems—areas where American companies maintain technological leads.\n\n## Securing America's AI Future\nThe $16.8 billion annual economic drain from AI chip smuggling represents just the visible portion of a much larger strategic challenge. As artificial intelligence reshapes the global economy, control over AI hardware translates directly into economic and security advantages. The United States cannot afford to allow these critical assets to flow uncontrolled to strategic competitors.\n\nThe window for effective action is narrowing. As China's indigenous semiconductor capabilities advance and AI systems become more powerful, the strategic importance of maintaining control over U.S. technology will only increase. The companies and nations that control advanced AI capabilities will shape the economic and security landscape for decades to come.\n\n*\"By implementing robust location verification systems today, we can ensure that American technological leadership translates into lasting economic and strategic advantages.\"*\n\nTechnology-enabled solutions offer a path forward that balances economic openness with security imperatives. By making smuggling prohibitively difficult and expensive, verification systems can help ensure that the benefits of American AI innovation flow primarily to American companies, workers, and allies—rather than subsidizing adversarial capabilities development.\n\nThe choice is clear: invest in sophisticated countermeasures now, or continue subsidizing competitors with America's most valuable technology. The economic and security stakes of this decision will compound for years to come, making today's policy choices among the most consequential of the AI era.\n\n## References\n¹ Analysis based on CNAS smuggling estimates (100,000 chips annually) and Nvidia ROI projections ($168,000 lifetime economic value per chip)\n\n² Calculated as: 100,000 smuggled chips × $168,000 average lifetime economic value = $16.8B annual economic transfer\n\n³ \"AI Diffusion Framework\" - Center for New American Security (CNAS), 2025\n\n⁴ \"NVIDIA H100 80GB AI-chip\" - ASA Computers and market analysis\n\n⁵ \"Memo - AI Diffusion\" - Center for New American Security, 2025\n\n⁶ \"NVIDIA's Crossroads: Navigating Geopolitical Storms\" - AInvest, 2025\n\n⁷ House Select Committee on Strategic Competition between the United States and the Chinese Communist Party, 2025\n\n⁸ \"Nvidia's AI Chip Dilemma: Navigating U.S. Regulations and Smuggling Risks in China\" - AInvest, 2025\n\n⁹ \"Nvidia Economics: Make $5-$7 for Every $1 Spent on AI-chips\" - HPCwire, 2024\n\n¹⁰ \"OpenAI Is A Systemic Risk To The Tech Industry\" - Where's Your Ed At, 2025\n\n¹¹ \"CoreWeave's IPO: A House of Cards Built on AI-chips and Microsoft?\" - AInvest, 2025\n\n¹² \"2025 global semiconductor industry outlook\" - Deloitte, 2025\n\n¹³ \"A new look at the economics of AI\" - MIT Sloan, 2025\n\n¹⁴ \"China's Technology Transfer Strategy\" - Kansas State University; \"China's Brute Force Economics\" - TNSR, 2022\n\n¹⁵ Various financial news sources reporting on DeepSeek market impact, January 2025\n\n¹⁶ \"Chairman Moolenaar, Bipartisan Lawmakers Unveil Bill to Stop AI Chip Smuggling to China\" - House Select Committee, 2025\n\n¹⁷ \"Can 'Location Verification' Stop AI Chip Smuggling?\" - AI Frontiers, 2025"
  },
  {
    "title": "Ping-Based Location Verification: 3 Deployment Scenarios",
    "slug": "ping-based-location-verification-3-deployment-scenarios",
    "date": "2025-05-30",
    "author": "Kristian Rönn",
    "tags": [
      "AI Security",
      "Location Verification",
      "National Security"
    ],
    "image": "/media/srv05vGqYGqH4olrQbiwjvybjw.png",
    "description": "Countering 'Dark Compute' and Illicit Proliferation: A Review of AI Chip Location Verification Methods.",
    "content": "# Ping-Based Location Verification: 3 Deployment Scenarios\n\n## Introduction: The Critical Need for Technology Enabled Location Verification\n\nIn today's rapidly evolving artificial intelligence landscape, verifying the physical location of high-performance computing hardware has become a paramount national security concern. Advanced AI chips, particularly those manufactured by industry leaders like Nvidia and AMD, have become highly sought-after components for nations looking to accelerate their AI capabilities. The illegal smuggling of these chips through shell companies and intermediary jurisdictions threatens to undermine export controls designed to protect national interests and global security.\n\nThe concept of \"dark compute\" - unmonitored computational resources that could enable malicious actors to develop dangerous capabilities - represents a significant threat to national security. Just as the international community monitors the proliferation of enriched uranium to prevent nuclear weapons development, there is an urgent need to implement robust technology-enabled verification systems for advanced computing hardware.\n\nCurrent export control regulations require end-user checks to verify compliance with licenses. It is untenable to imagine that humans can adequately and accurately account for every exported AI chip.\n\n## The Current Threat Landscape\n\nRecent intelligence indicates that hundreds of thousands of advanced AI chips are being illegally smuggled into restricted jurisdictions through elaborate networks of shell companies operating in countries like Malaysia and Singapore. These chips then power AI development that circumvents international safeguards and regulations. For example, reports suggest that the Chinese DeepSeek model was trained using tens of thousands of illegally imported Nvidia AI chips.\n\nThis circumvention has far-reaching consequences beyond direct security threats. When DeepSeek announced its capabilities, U.S. technology stocks reportedly experienced a $1 trillion decrease in value, demonstrating the economic impact of unauthorized AI development. Current regulations include a License Exception for Low-Power Performance (LPP), which exempts orders below the equivalent of 1,700 Nvidia H100 chips from certain controls. This creates a significant loophole that adversaries could exploit by establishing multiple shell companies to import chips below this threshold before aggregating them for large-scale AI supercomputing.\n\nTo address these critical challenges, three primary approaches to location verification have emerged. Each offers distinct advantages and limitations that make them suitable for different deployment scenarios.\n\n## 1. Co-located Approach: Maximum Security for High-Risk Environments\n\n![Co-located Approach Diagram](/media/NoiCf8zvTbRHtTACDNuH7nmL6k.svg)\n\n### Detailed Implementation\n\nThe co-located approach establishes a secure verification system within the physical confines of the datacenter itself. This system consists of three primary components:\n\n1. **Attestation Agent**: Embedded within the Trusted Execution Environment (TEE) of each AI chip, this agent securely communicates with the endorser server without the possibility of tampering.\n\n2. **Endorser Server**: A third-party controlled server housed within the datacenter's Local Area Network (LAN). This server is contained in a tamper-proof enclosure with specialized security features such as motion sensors, tamper-evident seals, and continuous monitoring systems.\n\nThe communication between these components occurs entirely within the datacenter's network, with the endorser server periodically sending cryptographically signed attestation reports during physical audits.\n\n### Advantages vs Limitations\n\n**Advantages:**\n- ✓ **Airgapped Compatibility**: Uniquely suited for Security Level 5 (SL5) datacenters that operate in complete isolation from external networks, essential for facilities handling classified information.\n- ✓ **Precise Location Verification**: With near-instantaneous communication between chips and the verification system, location can be verified down to specific rack or server level, making spoofing virtually impossible.\n- ✓ **Sensor Integration**: Enables connection to datacenter-specific sensors monitoring power usage, cooling systems, network interfaces, and hardware performance counters, creating a robust profile of legitimate activity.\n- ✓ **Enforcement Mechanisms**: Enables graduated response including processing throttling, workload isolation, emergency power termination, and even cooling system deactivation for severe violations.\n\n**Limitations:**\n- X **Vulnerability to Physical Tampering**: Despite tamper-proof enclosures, the endorser server remains physically accessible to datacenter personnel, creating potential attack vectors including electromagnetic analysis, side-channel attacks, and counterfeit hardware replacement.\n- X **Audit Complexity and Cost**: Auditors must conduct regular physical inspections. Their duties include securely downloading attestation records to a portable drive for off-site analysis and verifying that the endorser server has not been tampered with.\n- X **Single Point of Failure Risk**: If the endorser server is compromised or malfunctions, the entire verification system for that facility could be affected.\n\n### Ideal Use Cases\n\nThe co-located approach is best suited for:\n\n- Military and intelligence agency facilities developing AI for national security applications\n- Critical infrastructure protected by national security laws\n- Research facilities working on cutting-edge AI capabilities with dual-use potential\n- Government-operated supercomputing centers with strict security requirements\n\n## 2. Network Approach: Cost-Effective Solution for Lower-Risk Scenarios\n\n![Network Approach Diagram](/media/Sl5ipLHbP3A834JT2as8dX2hs.svg)\n\n### Detailed Implementation\n\nThe network approach leverages a distributed network of landmark servers operated by trusted third parties. This implementation includes:\n\n1. **Attestation Agent**: Similar to the co-located approach, this component resides within the TEE of each AI chip.\n\n2. **Landmark Server Network**: A geographically distributed network of trusted servers that communicate with the attestation agents. These landmarks can include servers in secure facilities like embassies, telecommunications hubs, certified datacenters, and government installations.\n\nThe verification process triangulates the chip's location by measuring network latency to multiple landmark servers, creating a unique network \"fingerprint\" that is difficult to falsify.\n\n### Advantages vs Limitations\n\n**Advantages:**\n- ✓ **Economic Efficiency**: Eliminates the need for additional hardware at each datacenter, reducing implementation costs, maintenance expenses, and administrative overhead.\n- ✓ **Minimal Operational Impact**: Simple software deployment to existing systems with no modifications to datacenter infrastructure and reduced compliance burden for legitimate operators.\n\n**Limitations:**\n- X **Location Accuracy Constraints**: Network routing complexities, congestion, and inherent limitations in distance measurement make precise location verification challenging, especially within 500km of restricted jurisdictions.\n- X **Incompatible with Airgapped Environments**: Cannot function in high-security facilities that operate without external network connections.\n- X **Limited Enforcement Options**: Restricted to software-level controls without direct access to hardware systems, reducing response capabilities for serious violations.\n\n### Ideal Use Cases\n\nThe network approach is best suited for:\n\n- Small-scale deployments with only a handful of AI-chips.\n- Cloud service providers offering AI acceleration to vetted customers\n- Academic and research institutions in low-risk jurisdictions\n- Commercial AI deployments with lower security requirements\n- Geographically isolated facilities far from restricted territories\n\n## 3. Hybrid Approach: Balanced Security for Most Enterprise Scenarios\n\n![Hybrid Approach Diagram](/media/7XJp5rlIJkKu3ImNbBFFpDXqEc.svg)\n\n### Detailed Implementation\n\nThe hybrid approach combines the strengths of both previous methods, creating a robust verification system that balances security and practicality:\n\n1. **Attestation Agent**: Similar to the co-located and network approach, this component resides within the TEE of each AI chip.\n\n2. **Co-located Endorser**: A tamper-resistant server installed within the datacenter's LAN, similar to the co-located approach.\n\n3. **Landmark Server Network**: Unlike the co-located approach, which requires frequent physical inspections to ensure the endorser hasn't been tampered with, this hybrid deployment scenario allows the endorser server to communicate with a broader network of landmark servers and other data center endorsers. This creates multiple layers of verification, ultimately requiring fewer physical inspections.\n\nThis approach implements a trust chain where the co-located endorser verifies the AI chips, while the network of landmarks continuously verifies the endorser itself.\n\n### Advantages vs Limitations\n\n**Advantages:**\n- ✓ **Multilayered Security Architecture**: Implements defense-in-depth with local verification for precise location confirmation and network verification to ensure the endorser itself hasn't been compromised.\n- ✓ **Reduced Audit Frequency**: Continuous remote attestation supplements in-person inspections, with automated anomaly detection triggering targeted audits only when necessary.\n- ✓ **Operational Flexibility**: Adaptable to different security requirements with configurable trust levels, graceful degradation during connectivity issues, and adjustable verification frequency.\n- ✓ **Enhanced Forensic Capabilities**: Creates comprehensive audit trails with correlation between local and network data, historical pattern analysis, and evidence preservation for potential legal proceedings.\n\n**Limitations:**\n- X **Not completely airgapped**: Unlike the pure co-located solution, a hybrid approach can't be completely airgapped, which means that it might not be suitable for military-grade security.\n- X **Moderate Cost Increase**: While less expensive than frequent physical audits, still requires initial hardware investment, ongoing maintenance, and security systems to protect the co-located endorser.\n\n### Ideal Use Cases\n\nThe hybrid approach is optimal for:\n\n- Enterprise AI deployments with significant security requirements\n- Datacenters in jurisdictions where export controls are a concern\n- Facilities with intermittent network connectivity\n- Systems processing sensitive but not classified information\n- Commercial entities working with government contracts\n\n## Comparative Metrics\n\n| Metric | Co-located Approach | Network Approach | Hybrid Approach |\n|--------|-------------------|------------------|----------------|\n| **Implementation Cost** | High (hardware + audits) | Low (software only) | Moderate (hardware + reduced audits) |\n| **Location Accuracy** | Extremely high (facility-specific) | Moderate (regional) | High (facility-specific) |\n| **Security Level** | Maximum | Basic | Enhanced |\n| **Audit Requirements** | Frequent physical audits | Minimal to none | Occasional physical audits |\n| **Network Dependency** | None (works in airgapped environments) | High (requires reliable internet) | Moderate (can function with intermittent connectivity) |\n| **Tamper Resistance** | High (physical enclosure) | Limited (software-based) | Enhanced (physical + network verification) |\n| **Enforcement Capabilities** | Comprehensive (hardware-level) | Limited (software-level) | Substantial (hardware + software) |\n| **Sensor Integration** | Extensive | None | Moderate to extensive |\n| **Scalability** | Limited by physical installation | Highly scalable | Moderately scalable |\n| **Operational Impact** | Moderate | Minimal | Low to moderate |\n| **Border Proximity Suitability** | Excellent | Poor within 500km of borders | Good |\n| **Recommended Deployment Size** | Large facilities (1000+ chips) | Small deployments (<500 chips) | Medium to large deployments (500+ chips) |\n\n## Conclusion\n\nThe proliferation of advanced AI chips to unauthorized entities represents a significant national security challenge comparable to the spread of nuclear technology. Implementing robust location verification systems is an essential component of a comprehensive strategy to prevent \"dark compute\" from enabling dangerous capabilities in the hands of malicious actors.\n\nEach of the three approaches offers distinct advantages that make them suitable for different deployment scenarios based on security requirements, budget constraints, and operational considerations. The co-located approach provides maximum security for critical facilities, the network approach offers cost-effective verification for lower-risk deployments, and the hybrid approach strikes an optimal balance for most enterprise scenarios.\n\nAs AI capabilities continue to advance, the importance of these verification systems will only increase. By implementing appropriate location verification based on risk assessment, organizations can help ensure that advanced computing resources remain in responsible hands while maintaining compliance with evolving regulatory frameworks."
  },
  {
    "title": "Security Guarantees in an America First AI Trade Policy",
    "slug": "security-guarantees-in-an-america-first-ai-trade-policy",
    "date": "2025-05-21",
    "author": "Kristian Rönn",
    "tags": [
      "National Security"
    ],
    "image": "media/9TLw1bo4Wr6uKJLQz8lRX6bp8.jpeg",
    "description": "Balancing bilateral dealmaking, semiconductor competitiveness, and national security in the age of artificial intelligence.",
    "content": "## Four Essential Properties of an America First AI Trade Policy\n\nFrom the Administration's perspective, an effective America First approach to AI trade policy should accomplish four critical objectives:\n\n1. Enable bilateral dealmaking leveraging America's AI chip advantage\n2. Ensure global competitiveness of U.S. semiconductor manufacturers\n3. Maintain the hardware edge for U.S.-based AI companies\n4. Prevent adversarial use of U.S. technology in weapons development and other security threats\n\nThese properties represent the foundation of a trade policy that is supposed to put American interests first—but balancing them requires sophisticated policy mechanisms. Let's examine each in detail.\n\n### 1. Enabling Bilateral Dealmaking Through AI Chip Access\n\nAI is becoming the most economically powerful technology in history. Within this administration, we'll likely see artificial general intelligence emerge. This could lead to a world where AI systems running on specialized chips handle nearly all important economic work. The administration has a unique opportunity: controlling who gets access to U.S.-made AI chips can become one of its strongest tools in global trade negotiations.\n\nThis advantage provides a basis for strategic cooperation, allowing the United States to engage in bilateral discussions that foster mutual economic growth and innovation across diverse sectors—from manufacturing to agriculture to services. By collaboratively managing access to these critical components, the administration can facilitate tailored agreements that benefit both American economic interests and the economic development of its partners.\n\n### 2. Ensuring U.S. Semiconductor Global Competitiveness\n\nSelling U.S.-developed and manufactured AI chips globally is essential for addressing trade imbalances and maintaining American dominance in semiconductor technology. The Trump administration's AI datacenter deals with the UAE and Saudi Arabia, worth billions of dollars, demonstrate how chip exports can significantly improve America's trade position.\n\nAmerican semiconductor giants like NVIDIA and AMD must maintain their global market position to ensure continued leadership in chip design and manufacturing. Restricting their ability to sell internationally would not only harm these companies financially but could ultimately diminish American innovation capabilities as competitors grow stronger.\n\n### 3. Maintaining the Hardware Edge for U.S. AI Companies\n\nHowever, to ensure the sustained leadership of American AI companies, it is crucial to manage the scale of access to advanced AI chips by foreign entities. This approach helps preserve the substantial advantages these U.S. firms currently hold in AI capabilities, revenue generation, and capital raised, which are largely due to their preferential access to cutting-edge AI hardware.\n\nThis hardware edge has been acknowledged not only by the CEOs of leading American AI companies but also by their international counterparts. The founder of Chinese AI company DeepSeek has publicly recognized that limited access to advanced computing resources has significantly hampered their ability to compete with U.S. firms.\n\n### 4. Preventing Adversarial Misuse of U.S. Technology\n\nCapable AI systems are recognized as a potential existential threat by the CEOs of all major AI labs, Nobel laureates, and the godfathers of modern AI. For this reason, it is critical that powerful AI capabilities don't fall into the hands of terrorists, dictatorial regimes, and U.S. adversaries.\n\nWhile AI offers enormous economic and social benefits, advanced models and large computing clusters could enable adversaries and malicious actors to enhance military and intelligence applications, lower barriers to developing weapons of mass destruction, support sophisticated cyber operations, and assist in human rights violations such as mass surveillance.\n\n## Navigating Competing Priorities Through Technology\n\nA fundamental tension exists between the first two properties (enabling bilateral dealmaking and ensuring semiconductor competitiveness) and the latter two (maintaining a U.S. AI hardware edge and preventing misuse). If universal access to U.S. AI semiconductors is provided, it risks eliminating the advantage enjoyed by American AI companies and lose control over potential misuse by adversaries.\n\nThe solution lies in implementing a proportional access framework: granting access to U.S. AI semiconductors based on the verifiable security guarantees that importers can provide. This approach allows the administration to finely calibrate its trade strategy, rewarding trusted partners while limiting access for less reliable actors.\n\n### 1. Access Proportional to Security Guarantees\n\nThe current regulatory framework for critical technologies employs tiered control levels based on destination, end-user, and item sensitivity. While this differentiated approach is appropriate, the allocation of access should be explicitly tied to the strength of verifiable, hardware-based security guarantees provided by the recipient.\n\nThis framework translates into crucial questions across the AI lifecycle:\n\n- **AI Inputs**: \"Where are the AI chips and other critical inputs located, and are global export controls being rigorously followed?\"\n- **AI Training**: \"Is a trained model undergoing and passing specific safety evaluations before deployment, with auditable and tamper-resistant records?\"\n- **AI Deployment**: \"Is the data of AI outputs and prompt logs being end-to-end encrypted, and in what jurisdiction is it stored, with assurances against unauthorized access?\"\n\n### 2. Development of Technical Standards\n\nCollaboration between the Bureau of Industry and Security (BIS), the National Institute of Standards and Technology (NIST), and U.S. industry is needed to develop comprehensive technical standards and reference architectures for crucial security protections. Standardizing requirements for tiered access will clarify expectations and accelerate the development of compliant solutions.\n\n### 3. Independent Third-Party Auditing\n\nCompliance with security standards must be verified through mandatory audits conducted by independent third parties. These auditors must be distinct from both U.S. exporters and foreign importers/end-users to ensure impartiality, similar to auditing practices in the financial sector.\n\n### 4. Funding and Competitiveness\n\nThe costs associated with implementing and auditing these crucial security guarantees will primarily be a responsibility of the foreign importers, reflecting their benefit from accessing advanced U.S. technology. Furthermore, the development of innovative hardware and software solutions required for compliance should foster growth among U.S. technology firms.\n\n## Conclusion\n\nBy implementing a system of proportional access based on verifiable security guarantees, the administration can balance competing priorities: enabling beneficial bilateral trade, maintaining U.S. semiconductor industry competitiveness, preserving the hardware edge for American AI companies, and preventing adversarial misuse of powerful technologies.\n\nThis balanced approach ensures that America's technological leadership translates into economic and strategic advantages while safeguarding national security. As AI continues its rapid development toward artificial general intelligence, the policies established today will determine whether the United States maintains its position at the forefront of this transformative technology—with all the economic and security benefits that leadership entails."
  }
]